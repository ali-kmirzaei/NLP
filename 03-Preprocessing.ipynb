{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMSMwOpxWLeEkNjo6L92emT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali-kmirzaei/NLP/blob/main/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libs"
      ],
      "metadata": {
        "id": "cv67paSvX1Bg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6V-WhT7WYiy"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import SnowballStemmer, LancasterStemmer,  PorterStemmer,WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqAobd4NbmIp",
        "outputId": "ce4470bc-ae8d-449d-d3d7-ed9bb353619c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize"
      ],
      "metadata": {
        "id": "CFQWk7IrX5Tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"I was going home when she rung. It was a surprise.\"\n",
        "sent_tokens = sent_tokenize(data.lower())\n",
        "word_tokens = word_tokenize(data.lower())\n",
        "sent_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOP2Hpz0WeXC",
        "outputId": "5fdfb25a-49b9-4240-80d9-9aadea91af44"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i was going home when she rung.', 'it was a surprise.']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming"
      ],
      "metadata": {
        "id": "ISeiCiYxYm7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "porter.stem('byed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s8bmqupsWltq",
        "outputId": "217d1a4c-19ce-4ec6-b7c8-8c655c22247d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'by'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Some Wrongs in stemming!**"
      ],
      "metadata": {
        "id": "xY1Qbbk8Xw6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plurals = ['universal','universe','university']\n",
        "singles = [porter.stem(plural) for plural in plurals]\n",
        "singles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pF7GkpMXFy1",
        "outputId": "6b8e6b00-0f56-44f9-d5c6-ea96f3c0e48b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['univers', 'univers', 'univers']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plurals = ['alumnus','alumni']\n",
        "singles = [porter.stem(plural) for plural in plurals]\n",
        "singles"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4fTiKnBXdmK",
        "outputId": "a90c35b3-a0bb-4325-d613-55bbd5025ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alumnu', 'alumni']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming - cont.**"
      ],
      "metadata": {
        "id": "IWt4YF0-ZwYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Here you can find activities to practise your reading skills. Reading will help you to improve your understanding of the language and build your vocabulary.The self-study lessons in this section are written and organised according to the levels of the Common European Framework of Reference for languages (CEFR). There are different types of texts and interactive exercises that practise the reading skills you need to do well in your studies, to get ahead at work and to communicate in English in your free time.Take our free online English test to find out which level to choose. Select your level, from beginner (CEFR level A1) to advanced (CEFR level C1), and improve your reading skills at your own speed, whenever it's convenient for you.\""
      ],
      "metadata": {
        "id": "CaVOTasNXqNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_eu = word_tokenize(text)\n",
        "\n",
        "porter = PorterStemmer()\n",
        "porter_eu = [porter.stem(word) for word in tokenized_eu]\n",
        "print(f\" PorterStemmer: {100*round(len(''.join(porter_eu))/len(''.join(word_tokenize(text))),3)}%\")\n",
        "\n",
        "snowball = SnowballStemmer(language='english')\n",
        "porter_eu = [snowball.stem(word) for word in tokenized_eu]\n",
        "print(f\" SnowballStemmer: {100*round(len(''.join(porter_eu))/len(''.join(word_tokenize(text))),3)}%\")\n",
        "\n",
        "lanc = LancasterStemmer()\n",
        "porter_eu = [lanc.stem(word) for word in tokenized_eu]\n",
        "print(f\" LancasterStemmerr: {100*round( len(''.join(porter_eu))/len(''.join(word_tokenize(text))),3 )}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD1MJA41aBbM",
        "outputId": "d68dfc24-4b20-4e8d-8902-8a5f877629bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PorterStemmer: 88.4%\n",
            " SnowballStemmer: 88.9%\n",
            " LancasterStemmerr: 77.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "porter_eu"
      ],
      "metadata": {
        "id": "WGH42NgbaRX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "eoBLjN5-bKyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "porter = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(f\" better\\n Stemming: {porter.stem('better')}\\n Lemmatization: { lemmatizer.lemmatize('better', pos ='a')}\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI2ryDZaaZzW",
        "outputId": "29542202-afae-40e7-d3be-5e06ccd764ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " better\n",
            " Stemming: better\n",
            " Lemmatization: good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example**"
      ],
      "metadata": {
        "id": "C5jlxkCUcXPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"There are mistakes\"\n",
        "print(f'Sentence: {sentence}')\n",
        "\n",
        "word_list = nltk.word_tokenize(sentence)\n",
        "print(f'word_list: {word_list}')\n",
        "\n",
        "lemmatized_output = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
        "print(f'Lemmatization: {lemmatized_output}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQf_NB6XbhMm",
        "outputId": "f37c73e2-665a-4e01-a89d-7c15624c0ced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: There are mistakes\n",
            "word_list: ['There', 'are', 'mistakes']\n",
            "Lemmatization: There are mistake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# POS"
      ],
      "metadata": {
        "id": "hb8YYba6cUYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"There are mistakes\"\n",
        "print(nltk.pos_tag(nltk.word_tokenize(sentence)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUhxIXRxcNwN",
        "outputId": "6d865edf-160f-4352-eb1c-a2e3f43cf1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('There', 'EX'), ('are', 'VBP'), ('mistakes', 'NNS')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "d48x6lc_coK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pos(word):\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    print(tag)\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print( ' '.join([lemmatizer.lemmatize(w, get_pos(w)) for w in nltk.word_tokenize(sentence)]))"
      ],
      "metadata": {
        "id": "-gvpnswQcV99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d63f65a3-c5e5-431f-af42-5b3d22d347e4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E\n",
            "V\n",
            "N\n",
            "There be mistake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CPRO4wcGd6CE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
